{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book recommandation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction: \n",
    "In this notebook, we implemented a model that select the 5 best sellers books of the New York Times that are the most related to the subject of an article. Therefore, each article will be linked to 5 books.\n",
    "Similary between a book and an article was assessed using the TF-IDF computation and the cosine similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/anavekua/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "import pprint\n",
    "import re\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load books data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load books data wich contains NYT bestsellers books information and books summary\n",
    "file_paths = \"data/bestsellers_with_abstract_and_genre_3350.json\"\n",
    "with open(file_paths, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Arts & Entertainment             55\n",
      "Biographies & Memoirs          1237\n",
      "Business & Personal Finance     166\n",
      "Comics & Graphic Novels           1\n",
      "Computers & Internet              3\n",
      "Cookbooks, Food & Wine            4\n",
      "Fiction & Literature             32\n",
      "Health, Mind & Body             113\n",
      "History                         387\n",
      "Humor                           121\n",
      "January 30                        1\n",
      "Kids                              1\n",
      "Lifestyle & Home                 22\n",
      "Mysteries & Thrillers             1\n",
      "N/A                             203\n",
      "Nonfiction                      199\n",
      "Parenting                        22\n",
      "Politics & Current Events       432\n",
      "Professional & Technical         48\n",
      "Reference                         2\n",
      "Religion & Spirituality          76\n",
      "Romance                           3\n",
      "Sci-Fi & Fantasy                  1\n",
      "Science & Nature                119\n",
      "Sports & Outdoors                80\n",
      "Travel & Adventure               19\n",
      "Young Adult                       2\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Books per category\n",
    "grouped_df = df.groupby('genre').count()\n",
    "print(grouped_df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove N/A category\n",
    "df = df[df['genre'] != 'N/A']\n",
    "\n",
    "# Select only books in 'Politics & Current Events'\n",
    "corpus_books = df[df['genre'] == 'Politics & Current Events']\n",
    "corpus_books = corpus_books.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NYT Articles data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data articles archives. This dataset contains all the archived political articles from the NYT. \n",
    "file_paths = \"/Users/anavekua/Documents/DataScienTest/API_nyt_json/nytimes_archives_elections_articles.json\"\n",
    "\n",
    "with open(file_paths, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "articles = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: Obama Ad Features Someone Big, Yellow and Feathery\n",
      "('A new television ad by President Obama’s campaign features Big Bird in a '\n",
      " 'tongue-in-cheek bid to attack Mitt Romney for suggesting he would crack down '\n",
      " 'on federal funding for public television, while not cracking down on big '\n",
      " 'banks.')\n"
     ]
    }
   ],
   "source": [
    "#Load an article from archive\n",
    "a = 100300 # article number\n",
    "article = articles.iloc[a, :]\n",
    "print(\"Headline:\", article['headline_main'])\n",
    "pprint.pprint(article['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data combination : Books and the selected article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>NEW YORK TIMES BESTSELLER • From bestselling a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>A NEW YORK TIMES, USA TODAY BESTSELLER! The Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>A new television ad by President Obama’s campa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              abstract\n",
       "430  NEW YORK TIMES BESTSELLER • From bestselling a...\n",
       "431  A NEW YORK TIMES, USA TODAY BESTSELLER! The Ne...\n",
       "432  A new television ad by President Obama’s campa..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all books abstracts with the article's abstract in one dataset\n",
    "corpus_article = article['abstract']\n",
    "corpus_books_article = pd.DataFrame(corpus_books['abstract'])\n",
    "corpus_books_article.loc[-1] = corpus_article # add article's abstract at the end of the df\n",
    "corpus_books_article = corpus_books_article.reset_index(drop=True)\n",
    "corpus_books_article.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and similarity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory:\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency. It is a common function used in text analysis and Natural Language Processing to calculate the similarity between documents. TF-IDF works by multiplying Term Frequency and Inverse Document Frequency. Term frequency represents how many times a term occurs in a document, and Inverse Document Frequency represents how common this word is across all documents.\n",
    "\n",
    "The TF-IDF matrix assigns a value (TF-IDF) for each document and each word. The similarity score across the matrix is then computed using cosine similarity computation. In summary, two documents will have higher similarity if they share more words between them and fewer words with other documents.\n",
    "\n",
    "TF-IDF requires the following text preprocessing:\n",
    "\n",
    "- The text data is preprocessed by removing stop words, punctuation, and other non-alphanumeric characters.\n",
    "- Tokenization: The text is tokenized into individual words.\n",
    "\n",
    "#### In practice:\n",
    "Our dataset is composed of book summaries, to which we will add the article abstract as the last row. Text preprocessing will be performed on the text documents. Then, we will apply the TF-IDF computation to the dataset. Cosine similarity will be calculated between the article's TF-IDF word values and the book summaries' TF-IDF word values. Finally, the 5 most similar books to the article will be displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text): \n",
    "    \n",
    "    import re \n",
    "    # Remove #1 from, for exemple, #1 NATIONAL BESTSELLER\n",
    "    remove_hastag1 = re.sub(r'\\#\\d', '', text)\n",
    "    # Remove all numbers \n",
    "    remove_numbers = re.sub(r'\\d+', '', remove_hastag1)\n",
    "    # Regular expression to match fully uppercase words and words containing uppercase letters\n",
    "    remove_full_upper = re.sub(r'\\b[A-Z]+\\b', '', remove_numbers)\n",
    "    # lowercasing\n",
    "    lowercased_text = remove_full_upper.lower()\n",
    "    # remove everything that is not a word character (including letters, digits and underscore) or a blank space. \n",
    "    remove_punctuation = re.sub(r'[^\\w\\s]', '', lowercased_text)\n",
    "    # Remove any sequence of one or more white space by one white space. Removes white spaces at begining and end of word. It also removes '\\xa0', Unicode for non-breaking space. \n",
    "    remove_white_space = re.sub(r'\\s+', ' ', remove_punctuation).strip()\n",
    "\n",
    "    return (remove_white_space)\n",
    "\n",
    "def tokenization(text_clean):\n",
    "    # Tokenization = Breaking down each text into words put in an array based on blank spaces.\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    tokenized_text = word_tokenize(text_clean)\n",
    "    return tokenized_text\n",
    "\n",
    "def remove_stop_words(abstract_token):\n",
    "# Stop Words/filtering = Removing irrelevant words\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "    stopwords_removed = [word for word in abstract_token if word not in stopwords]\n",
    "    return stopwords_removed\n",
    "\n",
    "# Stemming = Transforming words into their base form\n",
    "def stemming(abstract_stop_words):\n",
    "    from nltk.stem import PorterStemmer\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_text = [ps.stem(word) for word in abstract_stop_words]\n",
    "    return stemmed_text\n",
    "\n",
    "def preprocessing_abstract(abstract):\n",
    "    abstract_clean = text_cleaning(abstract)\n",
    "    abstract_token = tokenization(abstract_clean)\n",
    "    abstract_stop_words = remove_stop_words(abstract_token) \n",
    "    abstract_stemming = stemming(abstract_stop_words)\n",
    "    return abstract_stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data and save the preprocessed text in a new column. \n",
    "corpus_books_article['abstract_preprocessed'] = None\n",
    "col_index = corpus_books_article.columns.get_loc('abstract_preprocessed')\n",
    "\n",
    "# Loop through each abstract, preprocess it, transform list in string, update the DataFrame\n",
    "for index, abstract in enumerate(corpus_books_article['abstract']):\n",
    "    abstract_preprocessed = preprocessing_abstract(abstract)\n",
    "    string = ' '.join([str(item)for item in abstract_preprocessed])\n",
    "    corpus_books_article.iloc[index, col_index] = string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF - IDF computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus_books_article['abstract_preprocessed']) # return a document-term matrix\n",
    "\n",
    "# Get words \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Combine corpus with the weighted word matrix by creating 'id' index and merge\n",
    "corpus_books_article['id'] = range(0, len(corpus_books_article))\n",
    "df_tfidf_prev = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "df_tfidf_prev['id'] = range(0, len(df_tfidf_prev))\n",
    "df_tfidf = pd.merge(corpus_books_article, df_tfidf_prev, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10_most_important_words(row_num):\n",
    "    \"\"\"\n",
    "    return :\n",
    "    - the 10 top words with the highest weight based of a book abstract based on the row number\n",
    "    - the abstract\n",
    "    \"\"\"\n",
    "    abstract = df_tfidf.iloc[row_num, df_tfidf.columns.get_loc(\"abstract\")]\n",
    "    row = df_tfidf.iloc[row_num, df_tfidf.columns.get_loc(\"id\"):]\n",
    "    row_sort = row[1:].sort_values(ascending = False)\n",
    "    top_10_words = row_sort[:10]\n",
    "    return print(top_10_words), pprint.pprint(abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of Cosine similarity. The higher the cosim value, the more similar the elements are. \n",
    "cosim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "cosim = pd.DataFrame(cosim)\n",
    "cosim_article = cosim.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books to article selection (top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155</td>\n",
       "      <td>0.188388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168</td>\n",
       "      <td>0.130171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>0.107223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144</td>\n",
       "      <td>0.106198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>0.099749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    cosine\n",
       "0    155  0.188388\n",
       "1    168  0.130171\n",
       "2     82  0.107223\n",
       "3    144  0.106198\n",
       "4    139  0.099749"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the last row of the cosine matrix which represents the artcile cosine values to each books summary.\n",
    "cosim_artile_sort = cosim_article.iloc[-1,:].sort_values(ascending = False)\n",
    "\n",
    "# Select the 5 books that are the most similare to the article\n",
    "top_5_books = cosim_artile_sort[1:6]\n",
    "top_5_books = pd.DataFrame(top_5_books)\n",
    "top_5_books.columns = ['cosine']\n",
    "top_5_books = top_5_books.reset_index()\n",
    "top_5_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_books = corpus_books.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>book_uri</th>\n",
       "      <th>buy_links</th>\n",
       "      <th>genre</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82</td>\n",
       "      <td>THE ROOTS OF OBAMA'S RAGE</td>\n",
       "      <td>Dinesh D'Souza</td>\n",
       "      <td>Regnery</td>\n",
       "      <td>nyt://book/cfac8787-c017-5d12-ad52-387dbe48d29a</td>\n",
       "      <td>https://goto.applebooks.apple/9781596986251?at...</td>\n",
       "      <td>Politics &amp; Current Events</td>\n",
       "      <td>Critics of President Obama have attacked him a...</td>\n",
       "      <td>0.107223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139</td>\n",
       "      <td>BAILOUT</td>\n",
       "      <td>Neil Barofsky</td>\n",
       "      <td>Free Press</td>\n",
       "      <td>nyt://book/b1fcf65b-7534-5f60-bd17-0e44e4fcbd17</td>\n",
       "      <td>https://goto.applebooks.apple/9781451684940?at...</td>\n",
       "      <td>Politics &amp; Current Events</td>\n",
       "      <td>In this riveting account of the mishandling of...</td>\n",
       "      <td>0.099749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144</td>\n",
       "      <td>OBAMA'S LAST STAND</td>\n",
       "      <td>Glenn Thrush</td>\n",
       "      <td>Random House Publishing</td>\n",
       "      <td>nyt://book/f7476331-0deb-5d56-94fb-dbc3bb7648da</td>\n",
       "      <td>https://goto.applebooks.apple/9780679645092?at...</td>\n",
       "      <td>Politics &amp; Current Events</td>\n",
       "      <td>A series of four instant eBooks on the 2012 pr...</td>\n",
       "      <td>0.106198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>THE END OF THE LINE</td>\n",
       "      <td>Glenn Thrush and Jonathan Martin</td>\n",
       "      <td>Random House Publishing</td>\n",
       "      <td>nyt://book/073b4702-bff2-5f0d-92f2-aa67d7e60d2d</td>\n",
       "      <td>https://goto.applebooks.apple/9780679645108?at...</td>\n",
       "      <td>Politics &amp; Current Events</td>\n",
       "      <td>The fourth and final eBook in POLITICO’s Playb...</td>\n",
       "      <td>0.188388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168</td>\n",
       "      <td>THE CENTER HOLDS</td>\n",
       "      <td>Jonathan Alter</td>\n",
       "      <td>Simon &amp; Schuster</td>\n",
       "      <td>nyt://book/98e73896-4a4a-5652-b2ab-e7a451b72483</td>\n",
       "      <td>https://goto.applebooks.apple/9781451646108?at...</td>\n",
       "      <td>Politics &amp; Current Events</td>\n",
       "      <td>From the bestselling author of The Promise, th...</td>\n",
       "      <td>0.130171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                      title                            author  \\\n",
       "0     82  THE ROOTS OF OBAMA'S RAGE                    Dinesh D'Souza   \n",
       "1    139                    BAILOUT                     Neil Barofsky   \n",
       "2    144         OBAMA'S LAST STAND                      Glenn Thrush   \n",
       "3    155        THE END OF THE LINE  Glenn Thrush and Jonathan Martin   \n",
       "4    168           THE CENTER HOLDS                    Jonathan Alter   \n",
       "\n",
       "                 publisher                                         book_uri  \\\n",
       "0                  Regnery  nyt://book/cfac8787-c017-5d12-ad52-387dbe48d29a   \n",
       "1               Free Press  nyt://book/b1fcf65b-7534-5f60-bd17-0e44e4fcbd17   \n",
       "2  Random House Publishing  nyt://book/f7476331-0deb-5d56-94fb-dbc3bb7648da   \n",
       "3  Random House Publishing  nyt://book/073b4702-bff2-5f0d-92f2-aa67d7e60d2d   \n",
       "4         Simon & Schuster  nyt://book/98e73896-4a4a-5652-b2ab-e7a451b72483   \n",
       "\n",
       "                                           buy_links  \\\n",
       "0  https://goto.applebooks.apple/9781596986251?at...   \n",
       "1  https://goto.applebooks.apple/9781451684940?at...   \n",
       "2  https://goto.applebooks.apple/9780679645092?at...   \n",
       "3  https://goto.applebooks.apple/9780679645108?at...   \n",
       "4  https://goto.applebooks.apple/9781451646108?at...   \n",
       "\n",
       "                       genre  \\\n",
       "0  Politics & Current Events   \n",
       "1  Politics & Current Events   \n",
       "2  Politics & Current Events   \n",
       "3  Politics & Current Events   \n",
       "4  Politics & Current Events   \n",
       "\n",
       "                                            abstract    cosine  \n",
       "0  Critics of President Obama have attacked him a...  0.107223  \n",
       "1  In this riveting account of the mishandling of...  0.099749  \n",
       "2  A series of four instant eBooks on the 2012 pr...  0.106198  \n",
       "3  The fourth and final eBook in POLITICO’s Playb...  0.188388  \n",
       "4  From the bestselling author of The Promise, th...  0.130171  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the top 5 most similar books to the article\n",
    "top_5_books_info = pd.merge(corpus_books, top_5_books, how='inner', on='index')\n",
    "top_5_books_info.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
